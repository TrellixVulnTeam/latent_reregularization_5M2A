0it [00:00, ?it/s]
134it [00:00, 1337.18it/s]
268it [00:00, 1334.68it/s]
410it [00:00, 1356.35it/s]
535it [00:00, 1320.90it/s]
Traceback (most recent call last):
  File "/home/viper/anaconda3/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/viper/anaconda3/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/viper/anaconda3/lib/python3.6/site-packages/allennlp/run.py", line 18, in <module>
    main(prog="allennlp")
  File "/home/viper/anaconda3/lib/python3.6/site-packages/allennlp/commands/__init__.py", line 72, in main
    args.func(args)
  File "/home/viper/anaconda3/lib/python3.6/site-packages/allennlp/commands/train.py", line 111, in train_model_from_args
    args.force)
  File "/home/viper/anaconda3/lib/python3.6/site-packages/allennlp/commands/train.py", line 142, in train_model_from_file
    return train_model(params, serialization_dir, file_friendly_logging, recover, force)
  File "/home/viper/anaconda3/lib/python3.6/site-packages/allennlp/commands/train.py", line 282, in train_model
    all_datasets = datasets_from_params(params)
  File "/home/viper/anaconda3/lib/python3.6/site-packages/allennlp/commands/train.py", line 159, in datasets_from_params
    train_data = dataset_reader.read(train_data_path)
  File "/home/viper/anaconda3/lib/python3.6/site-packages/allennlp/data/dataset_readers/dataset_reader.py", line 73, in read
    instances = [instance for instance in Tqdm.tqdm(instances)]
  File "/home/viper/anaconda3/lib/python3.6/site-packages/allennlp/data/dataset_readers/dataset_reader.py", line 73, in <listcomp>
    instances = [instance for instance in Tqdm.tqdm(instances)]
  File "/home/viper/anaconda3/lib/python3.6/site-packages/tqdm/_tqdm.py", line 979, in __iter__
    for obj in iterable:
  File "/home/viper/anaconda3/lib/python3.6/site-packages/allennlp/data/dataset_readers/seq2seq.py", line 77, in _read
    yield self.text_to_instance(source_sequence, target_sequence)
  File "/home/viper/anaconda3/lib/python3.6/site-packages/allennlp/data/dataset_readers/seq2seq.py", line 88, in text_to_instance
    tokenized_target = self._target_tokenizer.tokenize(target_string)
  File "/home/viper/anaconda3/lib/python3.6/site-packages/allennlp/data/tokenizers/word_tokenizer.py", line 61, in tokenize
    words = self._word_splitter.split_words(text)
  File "/home/viper/anaconda3/lib/python3.6/site-packages/allennlp/data/tokenizers/word_splitter.py", line 155, in split_words
    return _remove_spaces(self.spacy(sentence))
  File "/home/viper/anaconda3/lib/python3.6/site-packages/spacy/language.py", line 340, in __call__
    doc = self.make_doc(text)
  File "/home/viper/anaconda3/lib/python3.6/site-packages/spacy/language.py", line 372, in make_doc
    return self.tokenizer(text)
  File "tokenizer.pyx", line 103, in spacy.tokenizer.Tokenizer.__call__
  File "tokenizer.pyx", line 157, in spacy.tokenizer.Tokenizer._tokenize
  File "tokenizer.pyx", line 236, in spacy.tokenizer.Tokenizer._attach_tokens
  File "vocab.pyx", line 130, in spacy.vocab.Vocab.get
  File "vocab.pyx", line 160, in spacy.vocab.Vocab._new_lexeme
  File "/home/viper/anaconda3/lib/python3.6/site-packages/spacy/lang/lex_attrs.py", line 137, in lower
    def lower(string): return string.lower()
KeyboardInterrupt

